{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "bLZk_rn6oaOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52758dd2-40e0-47e7-95a6-ff00cc097849"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mYT5yzirKb9",
        "outputId": "6d156dd6-5f62-4390-a584-9fe9c89ca210"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDFXZf7FbavX"
      },
      "source": [
        "# Atividade final avaliativa da disciplina de Processamento de Dados e Longa Escala \n",
        "## **Tutor**: Anderson Felipe Rocha\n",
        "##Alunos**: Caio Serpa, Eden Coelho e Roberto Sá\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c36GjogX5ktc"
      },
      "source": [
        "#Configuração do ambiente, instalação do hadoop e spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRKS6GpnbdaZ"
      },
      "outputs": [],
      "source": [
        "#instalar o Java 8 na maquina da sessão\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "#setando jdk 8\n",
        "#!sudo apt install openjdk-8-jdk\n",
        "#!sudo update-alternatives --config java \n",
        "\n",
        "#spark\n",
        "!wget -q https://ftp.unicamp.br/pub/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#extração do spark\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "#findspark para facilitar na criação da sessão spark\n",
        "!pip install -q findspark=\n",
        "!pip install  pyspark==3.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eTzi_8cOEzS"
      },
      "outputs": [],
      "source": [
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-sfw6A7bsUZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#variáveis de ambiente\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '\\\n",
        "    --driver-memory 10G \\\n",
        "    --executor-memory 10G \\\n",
        "    pyspark-shell'\n",
        "\n",
        "\n",
        "\n",
        "print(os.environ['JAVA_HOME'])\n",
        "print(os.environ['SPARK_HOME']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibj1draDb3ce"
      },
      "outputs": [],
      "source": [
        "!pip install findspark\n",
        "import findspark\n",
        "\n",
        "findspark.find()\n",
        "findspark.init()\n",
        "\n",
        "conf = SparkConf().setMaster(\"local[*]\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "#sc.stop()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gdbc3UfhwkNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUjLtTRg5tJG"
      },
      "source": [
        "#Importação do conjunto de dados\n",
        "\n",
        "Fonte dos dados: https://www.kaggle.com/datasets/najzeko/steam-reviews-2021?resource=download\n",
        "\n",
        "Tamanho do arquivo: 8.17GB\n",
        "Formato do arquivo: CSV\n",
        "\n",
        "Conjunto de dados de cerca de 21 milhões de avaliações de usuários de cerca de 300 jogos diferentes no Steam. Obtido usando a API fornecida pelo Steam descrita na documentação do Steamworks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnVcS5I3cXRC"
      },
      "outputs": [],
      "source": [
        "#recebendo os dados via api do google drive\n",
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTsOkCxxbave"
      },
      "outputs": [],
      "source": [
        "# Para quem usar Spark SQL\n",
        "from pyspark.sql.functions import to_timestamp\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "#data_spark = spark.read.csv('gdrive/My Drive/Colab Notebooks/steam_reviews.csv', header=True, inferSchema=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9ZeYhwW8QAR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "schema = StructType([\n",
        "    StructField('_c0', IntegerType(), False),\n",
        "    StructField('app_id',IntegerType(), False),\n",
        "    StructField('app_name', StringType(),False),\n",
        "    StructField('review_id',IntegerType(), False),\n",
        "    StructField('language', StringType(),False),\n",
        "    StructField('review', StringType(),False),\n",
        "    StructField('timestamp_created', LongType(), False),\n",
        "    StructField('timestamp_updated', LongType(), False),\n",
        "    StructField('recommended', BooleanType(), False),\n",
        "    StructField('votes_helpful',IntegerType(), False),\n",
        "    StructField('votes_funny',IntegerType(), False),\n",
        "    StructField('weighted_vote_score', FloatType(), False),\n",
        "    StructField('comment_count',IntegerType(), False),\n",
        "    StructField('steam_purchase', BooleanType(), False),\n",
        "    StructField('received_for_free', BooleanType(), False),\n",
        "    StructField('written_during_early_access', BooleanType(), False),\n",
        "    StructField('author.steamid', LongType(), False),\n",
        "    StructField('author.num_games_owned',IntegerType(), False),\n",
        "    StructField('author.num_reviews',IntegerType(), False),\n",
        "    StructField('author.playtime_forever', FloatType(), False),\n",
        "    StructField('author.playtime_last_two_weeks', FloatType(), False),\n",
        "    StructField('author.playtime_at_review', FloatType(), False),\n",
        "    StructField('author.last_played', StringType(), False),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8DlsCK-_kIi"
      },
      "outputs": [],
      "source": [
        "data_spark = spark.read.csv('/content/gdrive/MyDrive/Colab Notebooks/steam_reviews.csv', header=True, schema=schema)\n",
        "\n",
        "#data_spark = spark.read.csv('gdrive/My Drive/Colab Notebooks/steam_reviews.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeSP8oI27nvD"
      },
      "outputs": [],
      "source": [
        "data_spark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzXcAYcVYyHJ"
      },
      "outputs": [],
      "source": [
        "data_spark = data_spark.withColumnRenamed('_c0', 'id')\\\n",
        "            .withColumnRenamed('author.steamid', 'author_steamid')\\\n",
        "            .withColumnRenamed('author.num_games_owned', 'author_num_games_owned')\\\n",
        "            .withColumnRenamed('author.num_reviews', 'author_num_reviews')\\\n",
        "            .withColumnRenamed('author.playtime_forever', 'author_playtime_forever')\\\n",
        "            .withColumnRenamed('author.playtime_last_two_weeks', 'author_playtime_last_two_weeks')\\\n",
        "            .withColumnRenamed('author.playtime_at_review', 'author_playtime_at_review')\\\n",
        "            .withColumnRenamed('author.last_played', 'author_last_played').cache()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJV10kfbe_xl"
      },
      "outputs": [],
      "source": [
        "#data_spark.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvlig2Qf6Z3C"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9818ULlKMk-"
      },
      "outputs": [],
      "source": [
        "data_spark = data_spark.na.drop().cache()\n",
        "data_spark.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVjucT8ba609"
      },
      "outputs": [],
      "source": [
        "data_spark.show(10,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-rbqQ-NXNcE"
      },
      "outputs": [],
      "source": [
        "#data_spark.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujsX97bKWRmp"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "#função para remover o ponto e o zero da coluna autor_last_played\n",
        "get_number_without_dot = udf(lambda s: s.split('.')[0], StringType())\n",
        "data_spark = data_spark.withColumn('s_author_last_played', get_number_without_dot(data_spark.author_last_played)).cache()\n",
        "data_spark.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW4hms4ej7ie"
      },
      "outputs": [],
      "source": [
        "data_spark.show(10,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktvcdrAhj3DY"
      },
      "outputs": [],
      "source": [
        "#Convertendo para longType() a coluna s_author_last played\n",
        "data_spark = data_spark.withColumn('s_author_last_played',data_spark[\"s_author_last_played\"].cast(LongType())).cache()\n",
        "data_spark.count()\n",
        "#Convertendo para data as seguintes colunas\n",
        "data_spark  = data_spark.withColumn('s_author_last_played', from_unixtime(col('s_author_last_played')))\\\n",
        "          .withColumnRenamed('s_author_last_played','t_author_last_played')\\\n",
        "          .withColumn('t_timestamp_created', from_unixtime(col('timestamp_created')))\\\n",
        "          .withColumn('t_timestamp_updated', from_unixtime(col('timestamp_updated')))\\\n",
        "          .cache()\n",
        "\n",
        "#dropando colunas\n",
        "cols = (\"timestamp_created\",\"timestamp_updated\",\"author_last_played\")\n",
        "data_spark = data_spark.drop(*cols).cache()\n",
        "data_spark.count()\n",
        "\n",
        "data_spark.show(10,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8txVEA4ZHC05"
      },
      "outputs": [],
      "source": [
        "data_spark.coalesce(1).write.format(\"csv\").save(\"gdrive/MyDrive/clean_data\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}